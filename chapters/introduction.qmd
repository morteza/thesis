# Introduction

This is a book created from markdown and executable code.

See @knuth84 for additional discussion of literate programming.


+---------------+---------------+
| Title         | Linking Theories and Methods in Cognitive Sciences via Joint Embedding of the Scientific Literature: The Example of Cognitive Control
+---------------+---------------+
|| Challenge     | Gain clarity on what is meant by cognitive control in the scientific literature and how it can be measured empirically.
+---------------+---------------+
| Context       | Despite a large volume of publications, cognitive control remains a rather vague concept both theoretically and operationally (@REFs/baggetta). Literature reviews by human domain experts have had limited success in bringing such clarity: they are not exhaustive, can’t keep up with the rate of new publications, and may depict a biased, subjective perspective rather than an objective, quantitative view of the research field.
+---------------+---------------+
| Why it matters| Greater clarity on cognitive control and its measurement are critical to advance the field and integrate currently disparate research branches.
+---------------+---------------+
| Method        | We conducted automated text analysis on a large corpus of scientific abstract (+500K) downloaded from PubMed. We used a state-of-the-art language model (GPT-3) to encode scientific texts and create a joint view of cognitive control related constructs and tasks. This method allows the grounding of theoretical constructs on cognitive tasks (in the sense that tasks are used to measure the constructs) as well as the grounding of tasks on cognitive constructs (in the sense that constructs are used to theorize tasks). It also offers a unique holistic view of cognitive control constructs and tasks within a single knowledge graph.
+---------------+---------------+
| Results       | The results confirm the complex nature of cognitive control, explain the difficulty of defining cognitive control and may lead to new theoretical and empirical insights. We conclude that cognitive control can’t be assessed using a single task and should instead be measured using a battery of tasks (varying contexts and demands) or more complex tasks. We also conclude that as a construct cognitive control may benefit from being decomposed into smaller, better defined constructs to make progress in the field.
+---------------+---------------+
| Output        | The article was accepted as a conference paper for the CogSci2022 conference, the preprint is published on ArXiv ({@ansarinia2022}) and will be submitted for publication soon. The dataset is available on \url{https://huggingface.co/datasets/morteza/cogtext}, and the code is publicly available on \url{https://github.com/morteza/CogText}. <br />
|               | The methods and implications are further described in Article 1, page \pageref{chapters-cogtext}.
+---------------+---------------+

: Article 1 (CogText) {tbl-colwidths="[15,85]"}


```{=latex}

\begin{table}[ht!]
\renewcommand{\arraystretch}{1.5} %<- table vertical spacing
\caption{CogPonder}
\label{tbl-tldr-cogponder}
\begin{tabular}{|p{0.15\linewidth}|p{0.80\linewidth}|}
\hline
    \textbf{Title} & \RaggedRight{\bf Modeling Response Time in Cognitive Control Tasks using PonderNet Framework}  \\ \hline
    \textbf{Challenge} & \RaggedRight{Developing a shared account of response time for human data and artificial agents. \newline Understanding cognitive control would benefit from artificial models that are constrained by the numerous human capacities. One such defining (and measurable) property of human decision making is characterized by its gradual unfolding over time (i.e., response time; see @ratcliff2013 and @boeck2019).} \\ \hline
 &  \\ \hline
 &  \\ \hline
 &  \\ \hline
 &  \\ \hline
 &  \\ \hline
\end{tabular}
\end{table}
```
