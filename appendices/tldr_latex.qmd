
```{=latex}

\begin{table}[ht!]
\renewcommand{\arraystretch}{1.5} %<- table vertical spacing
\caption{Chapter 1 (CogText) information sheet}
\label{tbl-tldr-cogtext}
\begin{tabular}{|>{\raggedright\arraybackslash\columncolor[gray]{0.9}}p{.12\textwidth}|>{\raggedright\arraybackslash}p{0.88\textwidth}|}
\hline

\textbf{Title} & {\bf
    Linking Theories and Methods in Cognitive Sciences via Joint Embedding of the Scientific Literature: The Example of Cognitive Control
}  \\ \hline

\textbf{Challenge} & {
    Gain clarity on what is meant by cognitive control in the scientific literature and how it can be measured empirically.
} \\ \hline

\textbf{Context} & {
    Despite a large volume of publications, cognitive control remains a rather vague concept both theoretically and operationally (Baggetta \& Alexander, 2016). Literature reviews by human domain experts have had limited success in bringing such clarity: they are not exhaustive, can't keep up with the rate of new publications, and may depict a biased, subjective perspective rather than an objective, quantitative view of the research field.
} \\ \hline
\textbf{Why it matters} & {
    Greater clarity on cognitive control and its measurement are critical to advance the field and integrate currently disparate research branches.
} \\ \hline
\textbf{Methods} &  {
    We conducted automated text analysis on a large corpus of scientific abstract (+500K) downloaded from PubMed. We used a state-of-the-art language model (GPT-3) to encode scientific texts and create a joint view of cognitive control related constructs and tasks. This method allows the grounding of theoretical constructs on cognitive tasks (in the sense that tasks are used to measure the constructs) as well as the grounding of tasks on cognitive constructs (in the sense that constructs are used to theorize behavior in tasks). It also offers a unique holistic view of cognitive control constructs and tasks within a single knowledge graph.
} \\ \hline
\textbf{Results} & {
    The results confirm the complex nature of cognitive control, explain the difficulty of defining cognitive control and may lead to new theoretical and empirical insights. We conclude that cognitive control can't be assessed using a single task and should instead be measured using a battery of tasks (varying contexts and demands) or more complex tasks (e.g., video games). We also conclude that as a construct cognitive control may benefit from being decomposed into smaller, better defined constructs to make progress in the field.
} \\ \hline
\textbf{Output} & {
The article was accepted as a conference paper for the CogSci2022 conference, the preprint is published on ArXiv (Ansarinia, Schrater, \& Cardoso-Leite, 2022) and will be submitted for publication soon. The dataset is available on \href{https://huggingface.co/datasets/morteza/cogtext}{huggingface.co/datasets/morteza/cogtext}, and the code is publicly available on \href{https://github.com/morteza/CogText}{github.com/morteza/CogText}. \newline The methods and implications are further described in Chapter 1.
} \\ \hline
\end{tabular}
\end{table}
```



```{=latex}

\begin{table}[ht!]
\renewcommand{\arraystretch}{1.5} %<- table vertical spacing
\caption{Chapter 2 (CogEnv) information sheet}
\label{tbl-tldr-cogenv}
\begin{tabular}{|>{\raggedright\arraybackslash\columncolor[gray]{.9}}p{.12\textwidth}|>{\raggedright\arraybackslash}p{0.88\textwidth}|}
\hline

\textbf{Title} & {\bf
    CogEnv: A Virtual Environment for Contrasting Human and Artificial Agents across Cognitive Tests} \\ \hline
\textbf{Challenge} & {
    Modeling the environment: develop a virtual environment that allows the direct comparison of human versus artificial agents and thus supports the integration of cognitive control theories across psychology and artificial intelligence.
} \\ \hline
\textbf{Context} & {
    There have been important advances in artificial intelligence but those advances are not readily accessible to psychological scientists. Similarly, psychological scientists have developed tasks, concepts, and theories that might not be accessible or perceived as relevant by computer scientists. One impediment to a shared understanding is the lack of an interoperable environment in which both human and artificial agents can interact with the exact same tasks.
} \\ \hline
\textbf{Why it mattes} & {
    Being able to record and directly compare behavior from both human and artificial agents opens up many new possibilities. It may help ground cognition in computational terms [e.g., which types of tasks can be performed by a given computational architecture and which can't\; @yang2019; @mnih2015], offer benchmarks for human and artificial agents as well as their comparison (relative performance profiles), lead to the development of new tasks (e.g., tasks that are diagnostic of types of artificial agents and that could be tested on humans), and new computational models. It also allows to train a given artificial agent on a battery of tasks and to study task correlation and transfer effects (i.e., training on one task leads to improved performance on other tasks depending on how "similar" the tasks are) that can be compared with and tested on human participants.
} \\ \hline
\textbf{Methods} & {
    We developed CogEnv, a virtual environment that lets us interface both human and artificial agents to perform the exact same computerized battery of cognitive tasks. A wide range of artificial agents can be tested with this battery, provided they follow a common protocol (i.e., use pixels/symbols as input, process reward signals, and emit action). The data collected from these agents is in the same shape and format as human data and can thus be processed using the exact same data analysis code that is typical in experimental psychology (thus facilitating the direct comparison of human and artificial agents). As a proof of concept, we successfully trained baseline RL agents to perform a battery of cognitive tasks for which we also collected human data.
} \\ \hline
\textbf{Results} & {
    The overall framework is operational and appears very promising. A preliminary investigation illustrates the idea that the comparison of performance/error profiles of human versus baseline RL agents may reveal  aspects of human cognitive control that are yet to be addressed by artificial agents.
} \\ \hline
\textbf{Output} & {
    The article was accepted and published as a conference paper for the CCN2022 conference. The code is available at \href{https://github.com/morteza/CogEnv}{github.com/morteza/CogEnv}. \newline The method and implications of the proposed environment and expected performance profiles are further described in Chapter 2.
} \\ \hline

\end{tabular}
\end{table}
```



```{=latex}
\begin{table}[ht!]
\renewcommand{\arraystretch}{1.5} %<- table vertical spacing
\caption{Chapter 3 (CogPonder) information sheet}
\label{tbl-tldr-cogponder}
\begin{tabular}{|>{\raggedright\arraybackslash\columncolor[gray]{.9}}p{.12\textwidth}|>{\raggedright\arraybackslash}p{0.88\textwidth}|}
\hline

\textbf{Title} & {\bf
    CogPonder: Towards a Computational Framework of General Cognitive Control
} \\ \hline
\textbf{Challenge} & {
    Modeling the agent: developing a shared account of response times for human and artificial agents using a new type of computational model that functionally decouples control from controlled processes.
} \\ \hline
\textbf{Context} & {
    Computational models embody our theoretical understanding in an explicit and testable way. Current computational models of cognitive control are lacking in important ways. In psychology, cognitive control models tend to be designed for specific tasks (e.g., Stroop) which makes it hard to study cognitive control in general (e.g., across a battery of tasks, while playing video games or in real-life activities). Computer science, on the other hand, has recently been able to develop artificial agents that can perform complex tasks. However, computer scientists typically ignore resource limitations and how long it takes for an agent to make decisions and act (in some cases, the environment is "paused" for the agent computation to be completed). \newline A defining (and measurable) property of human cognitive processing is that it takes time and that this amount of time varies depending on numerous factors in a meaningful way (i.e., response time; [see @Ratcliff2013; @DeBoeck2019]). The exertion of cognitive control impacts response times and this impact is a major source of information in psychological research [e.g., "task-switching costs"\; @monsell2003]. \newline What is missing then is a new type of computational model of cognitive control that is flexible enough to be used in combination with any model (hence being able to address more complex tasks), which decouples control from operation in a way that might be theoretically meaningful and which offers computational scientists a means to add control mechanisms to their computational models.

} \\ \hline
\textbf{Why it mattes} & {
    The envisioned computational models would benefit psychology by offering a principled means to investigate cognitive control across a wide range of situations as well as the possibility to exploit innumerous complex models that have been developed in computer science. It would also benefit computer science by offering a principled and computationally practical (i.e., differentiable, modular) means to augment existing computational models with control abilities resulting in time varying responses. The comparison of response time profiles across human and artificial agents furthermore may offer insights benefitting both disciplines.
} \\ \hline
\textbf{Methods} & {
    We propose a general deep learning framework that functionally decouples control (generating varying response times) from the decision making processes (making choices). The framework involves a controller that acts as a wrapper around any computational models (that "perceive" the environment and generate "actions" on that environment) and controls when the model should stop its processing and output a choice (this is known as the halting problem). \newline This model is inspired by the Test-Operate-Test-Exit (TOTE) architecture [@Miller1960] that conceives control as a recurrent mechanism that ultimately halts a computational process once a specific condition has been met. We instantiated TOTE using PonderNet, a recent deep learning framework for adaptive computing. By controlling the halting, the fameworks allows to continuously control how much resources are dedicated to the decision making agent and jointly affects the choices (accuracy) and response speed of the system. \newline We implemented CogPonder, a flexible, differentiable end-to-end deep learning model that can perform the same cognitive tests that are used in cognitive psychology to test humans. We then trained CogPonder to perform two cognitive control tasks (i.e., Stroop and N-back)  while at the same time aligning it with human behavior. Next we compared the behavior of CogPonder  (i.e., accuracy and response times distributions)  with the behavior of humans.
} \\ \hline
\textbf{Results} & {
    CogPonder can be trained to perform cognitive tests and generates behavior that is similar to human behavior across multiple experimental conditions. CogPonder therefore provides a means for further investigating both human cognition and the computational models. \newline The proposed model is very flexible (i.e., CogPonder can wrap around any deep learning model so is unattached to specific model choices) and can be extended in many ways (e.g., using more advanced computational techniques to perform complex tasks). Most importantly, the proposed framework explicitly connects human behavior to artificial agents that produce human-like behaviors on a battery of cognitive control tasks. The framework thus provides interesting new insights and research opportunities for both psychological and computer science.
} \\ \hline
\textbf{Output} & {
    The manuscript will be submitted for publication soon. The code is available at \href{https://github.com/morteza/CogPonder}{github.com/morteza/CogPonder}. \newline The method and results of the proposed computational model of response time are further described in Chapter 3.
} \\ \hline

\end{tabular}
\end{table}
```


```{=latex}
\begin{table}[ht!]
\renewcommand{\arraystretch}{1.5} %<- table vertical spacing
\caption{Chapter 4 information sheet}
\label{tbl-tldr-review}
\begin{tabular}{|>{\raggedright\arraybackslash\columncolor[gray]{.9}}p{.12\textwidth}|>{\raggedright\arraybackslash}p{0.88\textwidth}|}
\hline

\textbf{Title} & {\bf 
    Training Cognition with Video Games
} \\ \hline
\textbf{Challenge} & {
    Clarifying the relationship between training cognitive control with action video games and its transfer effects by reviewing behavioral and brain evidence.
} \\ \hline
\textbf{Context} & {
    Experience impacts brain functioning and structure and there is now considerable evidence that specific training regimes can improve cognitive control. In particular, playing action video games, as opposed to other kinds of games, has been shown to cause improvements across a broad range of cognitive abilities [@bediou2018]. Although there is no satisfactory explanation of these effects yet, one prominent view states that video games improve cognitive/attentional control abilities and that this improvement in cognitive control explains the transfer effects [@green2012a].
} \\ \hline
\textbf{Why it mattes} & {
    Training cognition in a way that transfers to real life has many practical implications (e.g., rehabilitation, healthy aging, education, peak performance). Understanding the underlying mechanisms would allow us to devise more effective interventions.  The study of transfer effects is important because it offers a setting to test cognitive control theories in a non-trivial way. We currently have no satisfactory theory that could account for how training on one task would impact performance on a never seen before task. Understanding transfer requires developing computational models that can perform multiple tasks—this is a general goal that computational cognitive control models aim for. The study of training effects and their consequences is also important because they offer a means to causally test computational theories. Finally, the study of behavior during video game play poses interesting new questions to cognitive control scientists. Video games are complex interactive environments that engage cognitive systems in multiple, context dependent ways. Studying behavior during video game play may offer new insights on cognitive control that are relevant in the real world and that might not be apparent when using elementary cognitive tests.
} \\ \hline
\textbf{Methods} & {
    This chapter reviews the behavioral and neuroimaging literature on the cognitive consequences of playing various genres of video games.
} \\ \hline
\textbf{Results} & {
    Our review highlights that different genres of video games have different effects on cognition. Action video games—as defined by first and third person shooter games—have been associated with greater cognitive enhancement, especially when it comes to cognitive control and top-down attention, than puzzle or life-simulation games. Playing action video games seems also to impact reward processing, spatial navigation, and reconfiguration of attentional control networks in the brain. \newline Interpretations of the effects of playing action video games on behavior and the brain have been attributed to various psychological constructs, in particular attentional control, quick processing of sensory information, and rapid responses. \newline These results suggest that cognitive training interventions need to be endowed with specific game mechanics for them to generate cognitive benefits, presumably by enhancing cognitive control abilities. We discuss what those game mechanics might be and call for a more systematic assessment of the relationship between video game mechanics and cognition. We also note that as video games become more and more advanced (i.e., mixing genres and game-play styles within the same video game), it will become increasingly difficult to study and understand their effects on cognition. \newline This article lays a foundation for the study of cognitive and brain functioning using video games and illustrates the value of this approach to investigate general cognitive control.

} \\ \hline
\textbf{Output} & {
    The article has been published as a peer-reviewed book chapter [@cardoso-leite2021]. It is further provided in Chapter 4.
} \\ \hline

\end{tabular}
\end{table}
```


\newpage

```{=latex}
\begin{table}[ht!]
\small
\renewcommand{\arraystretch}{1.5} %<- table vertical spacing
\caption{Chapter 5 (ACNets) information sheet}
\label{tbl-tldr-acnets}
\begin{tabular}{|>{\raggedright\arraybackslash\columncolor[gray]{.9}}p{.12\textwidth}|>{\raggedright\arraybackslash}p{0.88\textwidth}|}
\hline

\textbf{Title} & {\bf
    Neural correlates of habitual action video games playing in control-related brain networks.
} \\ \hline
\textbf{Challenge} & {
    Test the idea that action video game play affects neural functioning in ways that are compatible with cognitive control hypotheses according to which action video gaming improves cognitive control which in turn explains improved performance across a wide range of cognitive tests (i.e., transfer).
} \\ \hline
\textbf{Context} & {
    On the one hand, research shows that playing action video games improves cognitive performance across a wide range of cognitive tasks, presumably by enhancing people's cognitive control abilities (Bediou et al., 2018). On the other, the cognitive neuroscience literature has highlighted integration of several functional brain networks as being important for cognitive control [@menon2020]. These two sets of theories have not yet been empirically confronted despite there being great value to do so. Indeed, there are competing hypotheses regarding the effects of action video gaming—some highlighting domain-general abilities (e.g., attention, cognitive control), others focusing on domain-specific ones (e.g., response speed). These alternative views make rather different predictions regarding changes in brain function (e.g., changes in specific functional networks vs changes in specific areas). \newline Similarly, research on functional brain networks has highlighted numerous cognitive control networks. There are however some inconsistencies across such theories. Studying the impact of playing action video games provides a means to empirically test those theories and improve our understanding of how those networks work.
} \\ \hline
\textbf{Why it mattes} & {
    The study of the differences in functional brain networks between habitual action video game players and non-video game players can advance our understanding of both the mechanisms underlying the action video game training effects and the neural mechanisms supporting cognitive control in general. \newline Confirming that action video game play affects cognitive control (via its functional neural underpinnings) has important implications for the study of cognitive training. It also has practical value as it would offer cognitive neuroscientists a new tool to causally study cognitive control. Finally, this type of work could lay a foundation towards bridging a gap between experimental psychology, cognitive neuroscience and computational cognitive sciences (brain function may for instance inspire new computational theories and behavioral experiments).
} \\ \hline
\textbf{Methods} & {
    We curated a dataset collected by [@föcker2018]. The dataset comprises resting-state fMRI data (7 minutes and 30 seconds, or 125 time points) and task-fMRI data from a total of 32 human subjects (16 habitual action video gamers and 16 non-gamers). The original study focused on task-fMRI; here we analyze the resting-state data. \newline We developed a machine learning pipeline to investigate the differences between habitual action video gamers and non-video gamers in terms of their functional resting-state brain connectivities, focusing in particular on networks associated with cognitive control. We used a robust approach to preprocess, remove confounds, parcellate, aggregate networks, and extract resting-state functional connectivity measures from the BOLD signals. The whole pipeline was cross-validated, and several arbitrary choices in the preprocessing were considered as hyperparameters of the model (for example parcellation atlas and connectivity measure). We trained a classifier to discriminate unseen participants as action video gamers versus non-gamers based on their resting-state functional connectivities. We then investigated what features were responsible for the model prediction accuracy by applying a permutation feature importance test. Additionally, SHAP analyses were conducted to investigate the contribution of each feature to the output (not the accuracy) of the model.
} \\ \hline
\textbf{Results} & {
    Our model is able to classify unseen participants as action video game players based only on their resting state functional connectivities with an accuracy of 72.6%. This high level of accuracy demonstrates the value of resting state functional data to study action video gaming. Interestingly, the performance of the classifier depended on the specifics of the method used (i.e., parcellation technique, type of connectivity metric), supporting the utility of the robust/exhaustive methodology employed in this study. Investigating why the classification was successful shows that there is in fact no specialized network that differs among the two groups of participants. Instead, it is the interplay between networks that matters most, and in particular the interplay between the cingulopercular and the sensorimotor networks and between the frontoparietal and the sensorimotor networks—a result that is robust to variations in parcellation and connectivity metric. These results do not support the view that individual networks are enhanced by action video game play and suggest instead a mechanism that involves a reconfiguration of a collection of networks. These results provide new insights and have clear implications for both theories of action video game training and for cognitive neuroscientific theories of cognitive control in the human brain. 
} \\ \hline
\textbf{Output} & {
    The article is being prepared for journal submission. The code is available on \href{https://github.com/morteza/ACNets}{github.com/morteza/ACNets}. The method and results are described in Chapter 5.
} \\ \hline

\end{tabular}
\end{table}
```
